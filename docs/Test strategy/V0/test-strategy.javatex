 packages ##
fontenc[T1]
color
amssymb
amsmath
eurosym
graphicx
textcomp
listings
epigraph
setspace
background[some]
gensymb
tikz
geometry
fancyhdr
babel[english]
##
 commands ##
scala.listing
scala-night.listing
##
 documentSettings ##
documentClass=report
alinea=4mm
chapterName=Part
##
 preprocessor ##

##
> title[titlePage.projet-merouTemplate] ##
date=February 16th, 2015
ref=model-checking.test-strategy
first_author_name=Sofia \textsc{Boutahar} ~\\ David \textsc{Courtinot}
title_size=0.9
sup_strip_color=0.70,0.70,0.70
inf_strip_color=0.00,0.00,0.00
title=Test strategy
version=1
##
>> chapter ##
Overview
##
>>> paragraph ##
The purpose of a test strategy is to clarify the major tasks and challenges of the test project, define what we want to accomplish and how we are going to achieve it. Moreover, it helps us figure out if there are missing requirements in the project and have a clear state of it at any point.
Our project is divided into two parts: The conversion of the AST to the CFG and the model checking using CTL.
The first part can be divided into two subparts : Parsing the file generated by the Clang compiler and converting the AST to the CFG.
##
>> chapter ##
Testing AST conversion to CFG
##
>>> section ##
Test strategy
##
>>>> paragraph ##
When we identify a particular problem in our code, we try to debug it and the fix the issues. 
To make sure that the fix works, we test our program again to see if it works. Therefore, it is not sufficient to validate the test if the tested program works, we should make sure that our fixes don't create some other problems in any other parts of our projects due to dependencies.
So, a set of related test cases may have to be repeated again, to make sure that nothing else is affected our fixes.
Basically, whenever there is a fix in one unit, we repeat all unit test cases for that unit in order to achieve a higher level of abstraction and quality.
##
>>> section ##
Testing the parser
##
>>>> paragraph ##
The clang compiler takes a C++ source code as input 
and returns a file describing an Abstract Syntax Tree. The purpose of creating a parser
is to extract from the Clang file all the useful information and build a tree
that contains it.
##
>>>> paragraph ##
As the number of possible tests for our parser is practically infinite, we created several tests
starting from the easiest to the most complicated one. The aim was to ensure that our
program is working for the minimum number of tests needed to get the coverage we want.
##
>>>> image ##
data/dowhile_clang.jpg;
Example of an input AST (generated automatically thanks to Clang by our test program) of a do-while statement;
0.3
##
>>>> image ##
data/while_astNode.jpg;
Corresponding output (ASTNode tree data-structure), as the test program prints it;
0.3
##
>>> section ##
Testing results
##
>>>> paragraph ##
We
##
>> chapter ##
Testing the model checking algorithm
##
>>> paragraph ##
Unlike the CFG part, there is a lot of room here for automated tests because there are many elementary operations that must return a specific result. We have written some generic methods 
that enable to automatically check the output rather than performing a manual check. This constitutes a very simple 
testing framework that we will present here. We will then present our process and results for the first iteration.
##
>>> section ##
Automated testing
##
>>>> paragraph ##
All the test functions rely on generic methods such as \textbf{assertEquals} or \textbf{assertTrue} that print
the result of the test with its number. This way, it is fairly easy to generate a log file and get the result of the tests
in the clearest way. You can find below an example of such test functions :
##
>>>> code ##
scala
def printMsg(failed: Boolean) = { 
        val msg = "\tTest %d %s".format(i,if (failed) "failed" else "passed") 
        if (failed) Console.err.println(msg)
        else        println(msg)
        i += 1
}
def assertEquals[T](t0: T, t1: T) = printMsg(t0 != t1)
def assertTrue(b: Boolean)       = printMsg(!b)
def compareEnv[T](envT1: Env[T], envT2: Env[T], expected: Env[T]) = assertEquals(envT1 interEnv envT2,    def testNeg[T](env: Env[T], envs: Env[T]*)  = assertEquals(!env,Set(envs: _*))
##
>>> section ##
Testing process
##
>>>> paragraph ##
For this part, we have made a lot of unitary tests. We first tested every operation defined on the Environment subclasses
because it constitutes the base of almost all computations performed by the algorithm. Once we were assured that these operations were correctly implemented,
we tested the operations of the ModelChecker, starting with the elementary operations to the compound operations. We still have not tested
the highest level functions.
##
>>> section ##
Results
##
>>>> paragraph ##
We detected and fixed some minor bugs in our elementary operations.  Globally, all the functions were implemented correctly.
Note that we had to rewrite those tests when we changed our conception for the CTL part. This was fairly easy thanks to the good structure of the code and we soon
obtained similar results. Just as an example, here is an example of the log generated by the automated tests.
##
>>>> image ##
data/test-log.png;
Example of a test log file;
0.7
##
